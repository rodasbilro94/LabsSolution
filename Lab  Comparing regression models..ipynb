{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dd8308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming we're trying to predict 'total_claim_amount' based on previous tasks\n",
    "X = customer_df.drop(columns=['total_claim_amount'])\n",
    "y = customer_df['total_claim_amount']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=31)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8991d954",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Separate X_train and X_test into numerical and categorical subsets\n",
    "X_train_num = X_train.select_dtypes(include=[np.number])\n",
    "X_test_num = X_test.select_dtypes(include=[np.number])\n",
    "X_train_cat = X_train.select_dtypes(exclude=[np.number])\n",
    "X_test_cat = X_test.select_dtypes(exclude=[np.number])\n",
    "\n",
    "# Encode the categorical variables using OneHotEncoder\n",
    "encoder = OneHotEncoder(drop='first').fit(X_train_cat)  # Fit on training data only\n",
    "X_train_cat_encoded = encoder.transform(X_train_cat).toarray()\n",
    "X_test_cat_encoded = encoder.transform(X_test_cat).toarray()\n",
    "\n",
    "# Convert encoded data into dataframes with appropriate column names and indexes\n",
    "X_train_cat_encoded_df = pd.DataFrame(X_train_cat_encoded, columns=encoder.get_feature_names_out(X_train_cat.columns), index=X_train_cat.index)\n",
    "X_test_cat_encoded_df = pd.DataFrame(X_test_cat_encoded, columns=encoder.get_feature_names_out(X_test_cat.columns), index=X_test_cat.index)\n",
    "\n",
    "X_train_cat_encoded_df.head(), X_test_cat_encoded_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ced7d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer, MinMaxScaler\n",
    "\n",
    "# 1. Use X_train_num to fit a power transformer\n",
    "power_transformer = PowerTransformer().fit(X_train_num)\n",
    "\n",
    "# 2. Transform both X_train_num and X_test_num\n",
    "X_train_num_transformed = power_transformer.transform(X_train_num)\n",
    "X_test_num_transformed = power_transformer.transform(X_test_num)\n",
    "\n",
    "# 3. Cast the resulting numpy arrays as pandas dataframes\n",
    "X_train_num_transformed_df = pd.DataFrame(X_train_num_transformed, columns=X_train_num.columns, index=X_train_num.index)\n",
    "X_test_num_transformed_df = pd.DataFrame(X_test_num_transformed, columns=X_test_num.columns, index=X_test_num.index)\n",
    "\n",
    "# 4. Concatenate the transformed numerical and encoded categorical dataframes\n",
    "X_train_new = pd.concat([X_train_num_transformed_df, X_train_cat_encoded_df], axis=1)\n",
    "X_test_new = pd.concat([X_test_num_transformed_df, X_test_cat_encoded_df], axis=1)\n",
    "\n",
    "# 5. Fit a MinMax scaler using X_train_new and transform X_train_new and X_test_new\n",
    "scaler = MinMaxScaler().fit(X_train_new)\n",
    "X_train_new_scaled = scaler.transform(X_train_new)\n",
    "X_test_new_scaled = scaler.transform(X_test_new)\n",
    "\n",
    "# Create new pandas dataframes from the resulting numpy arrays\n",
    "X_train_new_scaled_df = pd.DataFrame(X_train_new_scaled, columns=X_train_new.columns, index=X_train_new.index)\n",
    "X_test_new_scaled_df = pd.DataFrame(X_test_new_scaled, columns=X_test_new.columns, index=X_test_new.index)\n",
    "\n",
    "X_train_new_scaled_df.head(), X_test_new_scaled_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d185819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# 1. Train a simple linear regression model\n",
    "lin_reg = LinearRegression().fit(X_train_new_scaled_df, y_train)\n",
    "y_train_pred = lin_reg.predict(X_train_new_scaled_df)\n",
    "y_test_pred = lin_reg.predict(X_test_new_scaled_df)\n",
    "\n",
    "# 2. Create a function to evaluate model's predictions\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Returns a dataframe with various error metrics.\n",
    "    \"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    metrics = {\n",
    "        'Error_metric': ['MAE', 'MSE', 'RMSE', 'MAPE', 'R2'],\n",
    "        'Value': [mae, mse, rmse, mape, r2]\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame(metrics)\n",
    "\n",
    "# 3. Evaluate the linear model's predictions on the TRAIN and TEST sets\n",
    "train_evaluation = evaluate_model(y_train, y_train_pred)\n",
    "test_evaluation = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "train_evaluation, test_evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60faf5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "def train_models(models_list, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Train multiple models on the provided training data.\n",
    "    Returns a dictionary of trained models.\n",
    "    \"\"\"\n",
    "    trained_models = {}\n",
    "    for model in models_list:\n",
    "        model_instance = model()\n",
    "        model_instance.fit(X_train, y_train)\n",
    "        trained_models[model.__name__] = model_instance\n",
    "    return trained_models\n",
    "\n",
    "# Train the models using default settings\n",
    "models_to_train = [LinearRegression, KNeighborsRegressor, MLPRegressor]\n",
    "trained_models = train_models(models_to_train, X_train_new_scaled_df, y_train)\n",
    "\n",
    "# Evaluate the performance of the trained models on the TRAIN and TEST sets\n",
    "train_evaluations = {}\n",
    "test_evaluations = {}\n",
    "for model_name, model_instance in trained_models.items():\n",
    "    train_evaluations[model_name] = evaluate_model(y_train, model_instance.predict(X_train_new_scaled_df))\n",
    "    test_evaluations[model_name] = evaluate_model(y_test, model_instance.predict(X_test_new_scaled_df))\n",
    "\n",
    "train_evaluations, test_evaluations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1535ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "def train_models(models, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Trains a list of models and returns the trained models.\n",
    "    \"\"\"\n",
    "    for model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "    return models\n",
    "\n",
    "# List of models to be trained\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    KNeighborsRegressor(),\n",
    "    MLPRegressor(max_iter=1000)  # Increasing max_iter for convergence\n",
    "]\n",
    "\n",
    "# Training the models\n",
    "trained_models = train_models(models, X_train_new_scaled, y_train)\n",
    "\n",
    "# Evaluating the trained models on TRAIN set\n",
    "train_evaluations = [evaluate_predictions(y_train, model.predict(X_train_new_scaled)) for model in trained_models]\n",
    "\n",
    "# Evaluating the trained models on TEST set\n",
    "test_evaluations = [evaluate_predictions(y_test, model.predict(X_test_new_scaled)) for model in trained_models]\n",
    "\n",
    "train_evaluations, test_evaluations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d247298a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "def train_models(models, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Trains a list of models and returns the trained models.\n",
    "    \"\"\"\n",
    "    for model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "    return models\n",
    "\n",
    "# List of models to be trained\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    KNeighborsRegressor(),\n",
    "    MLPRegressor(max_iter=1000)  # Increasing max_iter for convergence\n",
    "]\n",
    "\n",
    "# Training the models\n",
    "trained_models = train_models(models, X_train_new_scaled, y_train)\n",
    "\n",
    "# Evaluating the trained models on TRAIN set\n",
    "train_evaluations = [evaluate_predictions(y_train, model.predict(X_train_new_scaled)) for model in trained_models]\n",
    "\n",
    "# Evaluating the trained models on TEST set\n",
    "test_evaluations = [evaluate_predictions(y_test, model.predict(X_test_new_scaled)) for model in trained_models]\n",
    "\n",
    "train_evaluations, test_evaluations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48b8735",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
